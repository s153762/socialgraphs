{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from fa2 import ForceAtlas2\n",
    "import io\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPyZ4dvDhQ_H"
   },
   "source": [
    "# Part 2: What do republican and democratic members tweet about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X3s2U3U1hXVP"
   },
   "source": [
    "_Exercise_ 4: TF-IDF of the republican and democratic tweets.\n",
    "\n",
    "We will create two documents, one containing the words extracted from tweets of republican members, and the other for Democratic members. We will then use TF-IDF to compare the content of these two documents and create a word-cloud. The procedure you should use is exactly the same you used in exercise 2 of week 7. The main steps are summarized below: \n",
    "* Create two large documents, one for the democratic and one for the republican party. Tokenize the pages, and combine the tokens into one long list including all the pages of the members of the same party. \n",
    "  * Exclude all twitter handles.\n",
    "  * Exclude punctuation.\n",
    "  * Exclude stop words (if you don't know what stop words are, go back and read NLPP1e again).\n",
    "  * Exclude numbers (since they're difficult to interpret in the word cloud).\n",
    "  * Set everything to lower case.\n",
    "  * Compute the TF-IDF for each document.\n",
    "* Now, create word-cloud for each party. Are these topics less \"boring\" than the wikipedia topics from a few weeks ago? Why?  Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zQ3r9_JhD3g"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "words() got an unexpected keyword argument 'encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fafaa1a3f39b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m#List of stop words + list of punctuation marks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mstop_punct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;31m#Tokenize the text in both files and filter the stopwords and punctuation marks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m#fileDem = open(\"Democratic.txt\", mode=\"r\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: words() got an unexpected keyword argument 'encoding'"
     ]
    }
   ],
   "source": [
    "#Creates an empty .txt-file\n",
    "f = io.open('Republican.txt', mode='w+', encoding='UTF-8')\n",
    "f.close()\n",
    "f = io.open('Democratic.txt', mode='w+', encoding='UTF-8')\n",
    "f.close()\n",
    "\n",
    "#Creates a list with all the politicians names from H115_tw.csv\n",
    "df = pd.read_csv('../../socialgraphs2018/files/data_twitter/H115_tw.csv')\n",
    "politicians = list(df['tw_name'])\n",
    "\n",
    "for n in politicians:\n",
    "    f = io.open('../../socialgraphs2018/files/data_twitter/tweets/'+n, mode=\"r\", encoding='UTF-8')\n",
    "    str = f.read()\n",
    "    \n",
    "    #Excludes all twitter handles, RT, hyperlinks, numbers.\n",
    "    regx_list = ['@\\w*', 'RT', '(http|https):\\/\\/\\w*.\\w*\\/\\w*', '\\d']\n",
    "    for regx in regx_list:\n",
    "        str = re.sub(regx, '', str)\n",
    "    \n",
    "    #Set everything to lower case.\n",
    "    str = str.lower()\n",
    "    \n",
    "    #Fills the two .txt-files with tweets from all the politicians. \n",
    "    #One with tweets from Republicans and one with tweets from Democrats\n",
    "    if df[df.tw_name==n]['Party'].values[0] == 'Democratic':\n",
    "        f = io.open('Democratic.txt', mode='a+', encoding='UTF-8')\n",
    "        f.write(str+\" \")\n",
    "        f.close()\n",
    "    else:\n",
    "        f = io.open('Republican.txt', mode='a+', encoding='UTF-8')\n",
    "        f.write(str+\" \")\n",
    "        f.close()\n",
    "        \n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "#List of stop words + list of punctuation marks\n",
    "stop_punct = stopwords.words('english', encoding='UTF-8') + list(string.punctuation)\n",
    "#Tokenize the text in both files and filter the stopwords and punctuation marks \n",
    "#fileDem = open(\"Democratic.txt\", mode=\"r\")\n",
    "#textDem = fileDem.read()\n",
    "#filterDem = [word for word in word_tokenize(textDem) if word not in stop_punct]\n",
    "fileRep = open(\"Republican.txt\", mode=\"r\")\n",
    "textRep = fileRep.read()\n",
    "filterRep = [word for word in word_tokenize(textRep) if word not in stop_punct]\n",
    "\n",
    "#print(filterDem[:10])\n",
    "print(filterRep[:10])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Assignment 2",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
